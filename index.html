<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en-us lang=en-us><head><link href=https://gmpg.org/xfn/11 rel=profile><meta charset=utf-8><meta name=generator content="Hugo 0.117.0"><meta name=viewport content="width=device-width,initial-scale=1"><title>by Alex Code blog</title><meta name=keywords content="software,development,solution architecture,azure,aws,devops,automation,blog,articles"><meta name=description content="Smart thoughts... and not very smart too!"><link type=text/css rel=stylesheet href=https://byalexblog.net/css/print.css media=print><link type=text/css rel=stylesheet href=https://byalexblog.net/css/poole.css><link type=text/css rel=stylesheet href=https://byalexblog.net/css/syntax.css><link type=text/css rel=stylesheet href=https://byalexblog.net/css/hyde.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700"><link rel=apple-touch-icon-precomposed sizes=144x144 href=/apple-touch-icon-144-precomposed.png><link rel="shortcut icon" href=/favicon.png><link href=https://byalexblog.net/index.xml rel=alternate type=application/rss+xml title="by Alex Code blog"></head><body><aside class=sidebar><div class=container><div class=sidebar-about><a href=https://byalexblog.net/><h1>by Alex Code blog</h1></a><p class=lead>Smart thoughts... and not very smart too!</p></div><nav><ul class=sidebar-nav><li><a href=https://byalexblog.net/>Home</a></li><li><a href=https://byalexblog.net/article>Articles</a></li><li><a href=https://github.com/lanubisl target=_blank>Github</a></li><li><a href=https://www.linkedin.com/in/panfilenok target=_blank>LinkedIn</a></li></ul></nav><p>&copy; 2023. All rights reserved.</p></div></aside><main class="content container"><div class=posts><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/react-azure-storage/>Host React frontend app on Azure Storage Account</a></h1><time datetime=2023-08-19T11:56:40Z class=post-date>Sat, Aug 19, 2023</time>
<img src=/images/react-azure-storage/react-azure-storage-logo.jpg alt> Running a React frontend web application on an Azure Storage account is a great way to host your app with a low cost and high scalability. In this post, we&rsquo;ll go through the steps of setting up a new Azure Storage account and deploying your React app to it.<div class=read-more-link><a href=/article/react-azure-storage/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/azure-apimanagement-to-azure-service-bus/>Azure API Management to Azure Service Bus</a></h1><time datetime=2023-07-08T10:19:45Z class=post-date>Sat, Jul 8, 2023</time>
<img src=/images/azure-apimanagement-to-azure-service-bus/apim_to_sb.jpg alt>
In my <a href=https://byalexblog.net/article/azure-apimanagement-to-azure-storage-account/>previous post</a> I showed how to use <a href=https://azure.microsoft.com/en-us/products/api-management>Azure API Management</a> to expose an <a href=https://learn.microsoft.com/en-us/azure/storage/common/storage-account-overview>Azure Storage Account</a>. In this post I will show how to use Azure API Management to expose an <a href=https://learn.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messaging-overview>Azure Service Bus</a>.
This combination is useful when you have a fire and forget HTTP endpoint and you expect irregular traffic. For example, you are designing a mobile application crash reporting system. You want to send the crash report to the server and forget about it. You don&rsquo;t want to wait for the response. You don&rsquo;t want to block the user interface. You don&rsquo;t want to retry if the server is not available. It might happen that a new mobile app version has a significant bug and you get a lot of crash reports. In this case, it is reasonable to use Azure Service Bus to queue the crash reports for peak times and process them later.
As in my <a href=https://byalexblog.net/article/azure-apimanagement-to-azure-storage-account/>previous post</a>, I will use a scenario with two brands (Adidas and Nike) to show you the flexibility of the combination Azure API Management plus Azure Service Bus. I will also define everything in <a href=https://www.terraform.io/>Terraform</a> so the solution deployment is fully automated.<div class=read-more-link><a href=/article/azure-apimanagement-to-azure-service-bus/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/azure-apimanagement-to-azure-storage-account/>Azure API Management to Azure Storage Account</a></h1><time datetime=2023-07-06T08:32:23Z class=post-date>Thu, Jul 6, 2023</time>
<img src=/images/azure-apimanagement-to-azure-storage-account/apim_to_blob.jpg alt> There can be the case when you need to upload a file or metadata to <a href=https://learn.microsoft.com/en-us/azure/storage/common/storage-account-overview>Azure Storage Account</a> from an application which is outside of your cloud infrastructure. You should not expose your storage account to the internet for that purpose. There are many reasons for that: securuty, flexibility, monitoring etc. The natural solution to acheave the goal is to use something in between of your Azure Storage Account and the public internet. Some kind of HTTP proxy that will manage user authentication, do some simple validations and then pass the request to Storage Account to save the request body data as a blob. <a href=https://azure.microsoft.com/en-us/products/api-management>Azure API Management</a> is a perfect candidate for that role. It is a fully managed service that means you don&rsquo;t need to create any custom application. It is highly available and scalable. It has a lot of features that can be used for your needs.
In this article I will show how to configure Azure API Management to upload a file to Azure Storage Account.<div class=read-more-link><a href=/article/azure-apimanagement-to-azure-storage-account/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/azure-sql-schema-deployment/>Breaking Through Barriers: Simplifying CD with Automated Azure SQL Schema Changes!</a></h1><time datetime=2023-06-10T10:57:21Z class=post-date>Sat, Jun 10, 2023</time>
<img src=/images/azure-sql-schema-deployment/logo.jpg alt> Have you ever tried to deploy a Microsoft SQL database schema to Azure SQL using a linux-based CI/CD pipeline? If you did, you probably know that it is not a trivial task. The reason is that the <a href=https://www.nuget.org/packages/Microsoft.Data.Tools.Msbuild>Microsoft.Data.Tools.Msbuild</a> package is not available for linux. The package contains MSBuild targets and properties that are used to build and deploy database projects. The package is a part of <a href="https://docs.microsoft.com/en-us/sql/ssdt/download-sql-server-data-tools-ssdt?view=sql-server-ver15">SQL Server Data Tools (SSDT)</a> and it is not available for linux. So if you want to deploy a database schema to Azure SQL using a linux-based CI/CD pipeline you need to use a different approach. In this article we will see how to deploy a Microsoft SQL database schema to Azure SQL using <strong>any</strong> linux-based CI/CD pipeline (Gitlab, GitHub, Azure DevOps, etc).<div class=read-more-link><a href=/article/azure-sql-schema-deployment/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/azure-function-serverless-deployment-python/>Azure Function Serverless Deployment Python</a></h1><time datetime=2023-05-26T12:03:58Z class=post-date>Fri, May 26, 2023</time>
<img src=/images/azure-function-serverless-deployment-python/logo.jpg alt> Consumption plan is the cheapest way to run your Azure Function. However, it has some limitations. For example, you can not use Web Deploy, Docker Container, Source Control, FTP, Cloud sync or Local Git. You can use <a href=https://learn.microsoft.com/en-us/azure/azure-functions/functions-deployment-technologies#external-package-url>External package URL</a> or <a href=https://learn.microsoft.com/en-us/azure/azure-functions/functions-deployment-technologies#zip-deploy>Zip deploy</a> instead. In this article I will show you how to deploy Python Azure Function <a href=https://techcommunity.microsoft.com/t5/azure-compute-blog/azure-functions-v2-python-programming-model/ba-p/3665168>Programming Model v2</a> App to Linux Consumption Azure Function resource using Zip Deployment.<div class=read-more-link><a href=/article/azure-function-serverless-deployment-python/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/azure-function-serverless-deployment-dotnet/>Azure Function Serverless Deployment Dotnet</a></h1><time datetime=2023-05-24T18:53:32Z class=post-date>Wed, May 24, 2023</time>
<img src=/images/azure-function-serverless-deployment-dotnet/logo.jpg alt> Consumption plan is the cheapest way to run your Azure Function. However, it has some limitations. For example, you can not use Web Deploy, Docker Container, Source Control, FTP, Cloud sync or Local Git. You can use <a href=https://learn.microsoft.com/en-us/azure/azure-functions/functions-deployment-technologies#external-package-url>External package URL</a> or <a href=https://learn.microsoft.com/en-us/azure/azure-functions/functions-deployment-technologies#zip-deploy>Zip deploy</a> instead. In this article I will show you how to deploy Dotnet Isolated Azure Function App to Linux Consumption Azure Function resource using Zip Deployment.<div class=read-more-link><a href=/article/azure-function-serverless-deployment-dotnet/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/dapper-queries-synchronized-with-mssql-database-schema/>Dapper queries synchronized with MSSQL database schema</a></h1><time datetime=2022-08-25T12:43:45+0200 class=post-date>Thu, Aug 25, 2022</time>
<img src=/images/dapper-queries-synchronized-with-mssql-database-schema/logo.jpg alt> Dapper is a MicroORM that allows you to control SQL queries you are executing and removes the pain of mapping the dataset results back to your domain model. The thing is that when you specify SQL queries you have to make sure they are valid against the current Database schema. One solution is to use Stored Procedures&mldr; other one is this&mldr;<div class=read-more-link><a href=/article/dapper-queries-synchronized-with-mssql-database-schema/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/aws-certificatemanager-tls-cert-import/>AWS Certificate Manager TLS Certificate import</a></h1><time datetime=2022-08-23T11:18:30+0200 class=post-date>Tue, Aug 23, 2022</time>
When you are going to use TLS certificate with AWS CloudFront, AWS Elastic Load Balancing, AWS API Gateway or other integrated services you can use that by importing the certificate data to the AWS Certificate Manager.<div class=read-more-link><a href=/article/aws-certificatemanager-tls-cert-import/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/dotnet6-elasticbeanstalk/>Deploying dotnet6 app on AWS ElasticBeanstalk Graviton2 with HTTPS termination on EC2 instance</a></h1><time datetime=2022-08-22T10:20:06+0200 class=post-date>Mon, Aug 22, 2022</time>
On one of my project it was a requirement to reduce the ElasticBeanstalk hosting costs to minimum for dotnet application. The app is a kind of dashboard with limited audience and nothing heavy inside. I decided to use Graviton2 instances (ARM processors on board) in order to acheave best speed/cost ratio.<div class=read-more-link><a href=/article/dotnet6-elasticbeanstalk/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/linux-nas-drive-format-command/>My current command to format hard drive for linux NAS</a></h1><time datetime=2021-08-03T21:22:05+0300 class=post-date>Tue, Aug 3, 2021</time>
Put it here to just not forget =) Here is my command to format my hard drives for NAS. I came to this when I bought 2 10TB hard drives for Chia coin mining. <code>bash sudo mkfs.ext4 /dev/sde1 -T largefile4 -m 0</code><div class=read-more-link><a href=/article/linux-nas-drive-format-command/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/azure-api-management-automated-revisions/>Azure Api Management Automated Revisions</a></h1><time datetime=2021-07-28T23:41:05+0300 class=post-date>Wed, Jul 28, 2021</time>
Powershell script to deploy new WebAPI and release new API Management revision with zero downtime.<div class=read-more-link><a href=/article/azure-api-management-automated-revisions/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/future-for-business-analysts/>Future for business analysts</a></h1><time datetime=2016-10-20T12:12:40+0300 class=post-date>Thu, Oct 20, 2016</time>
Software products can be much better if anybody start asking questions about who will use it. We need user researchers called Interaction Designers (IxD) that will prove we are creating something that can be used by people. Where to find them? Business analysts are best people to start looking.<div class=read-more-link><a href=/article/future-for-business-analysts/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/3-steps-integration-testing-aspnet-mvc/>3 steps to create integration tests for your ASP.NET MVC 5 application</a></h1><time datetime=2016-10-02T09:43:29+0300 class=post-date>Sun, Oct 2, 2016</time><p><img src=/images/3-steps-integration-testing-aspnet-mvc/integration-testing-mock-component.png alt>
When you develop an ASP.NET MVC application you should test it anyway. You can cover different parts of your application logic with unit tests or you can create tests that look like user interaction scenarios. These tests have several advantages over unit tests:</p><ul><li>These tests are independent of implementation and you can&rsquo;t break your test by refactoring (the only scenario when you should modify your test is functional requirement change).</li><li>These tests are good documentation for your application.</li><li>These tests can give you idea about that your users need and how will they supposed to use concrete feature.</li></ul><div class=read-more-link><a href=/article/3-steps-integration-testing-aspnet-mvc/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/merge-sql-databases/>Merge SQL databases</a></h1><time datetime=2016-05-27T11:55:25+0300 class=post-date>Fri, May 27, 2016</time>
Imagine you have 2 databases with identical schema. These databases were working for different application instances for some time. And now you need to merge them together for some reason. You can use different tools to achieve this goal. For example <a href=https://www.devart.com/ru/dbforge/sql/datacompare/>dbForge Data Compare</a> or <a href=http://www.red-gate.com/products/sql-development/sql-data-compare/>SQL Data Compare</a>. But these tools cost money and if you don&rsquo;t merge databases every day this is probably not an option for you. Also these tools does not know full specific of your database structure including unique indexes, check constraints and triggers. Another big deal is identity columns that are using as primary keys. For two databases these keys can be same but represent different entities.  In my practice I face database merge task second time and here is how I handle it.<div class=read-more-link><a href=/article/merge-sql-databases/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/rabbitmq-poisoned-messages-handeling/>RabbitMQ poisoned messages handling</a></h1><time datetime=2016-02-09T22:59:03+0300 class=post-date>Tue, Feb 9, 2016</time>
You never know what will come from remote system. Even if you keep everything under control, there always can be something unexpected. In microservice architecture each component must be ready for everything.<div class=read-more-link><a href=/article/rabbitmq-poisoned-messages-handeling/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/custom-domain-name-for-azure-vm/>Custom domain name for Azure VM</a></h1><time datetime=2015-10-04T23:33:03+0300 class=post-date>Sun, Oct 4, 2015</time>
If you are running VM on Azure you know that your default domain name looks like this: <code>yourservicename.cloudapp.net</code>. Also public IP address is not static that means you can&rsquo;t use &lsquo;A&rsquo; DNS record on it.<div class=read-more-link><a href=/article/custom-domain-name-for-azure-vm/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/using-msbuild-to-deploy-composite-web-application/>Using MSBuild to deploy composite web application</a></h1><time datetime=2015-04-30T17:30:52+0300 class=post-date>Thu, Apr 30, 2015</time>
How to deploy AngularJS + ASP.NET Web.API application using MSBuild<div class=read-more-link><a href=/article/using-msbuild-to-deploy-composite-web-application/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/the-biggest-problem-of-all-software-developers/>The biggest problem of all software developers</a></h1><time datetime=2015-03-29T11:16:38+0300 class=post-date>Sun, Mar 29, 2015</time>
The biggest problem of all software developers<div class=read-more-link><a href=/article/the-biggest-problem-of-all-software-developers/>Read More…</a></div></article><article class=post><h1 class=post-title><a href=https://byalexblog.net/article/entity-framework-dynamic-columns/>Reading user defined columns from database with Entity Framework</a></h1><time datetime=2015-03-12T20:43:25+0300 class=post-date>Thu, Mar 12, 2015</time>
Reading user defined columns from database with Entity Framework<div class=read-more-link><a href=/article/entity-framework-dynamic-columns/>Read More…</a></div></article></div></main><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-44968940-4","auto"),ga("send","pageview"))</script></body></html>