<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Articles on by Alex Code blog</title><link>https://byalexblog.net/article/</link><description>Recent content in Articles on by Alex Code blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 19 Aug 2023 11:56:40 +0000</lastBuildDate><atom:link href="https://byalexblog.net/article/index.xml" rel="self" type="application/rss+xml"/><item><title>Host React frontend app on Azure Storage Account</title><link>https://byalexblog.net/article/react-azure-storage/</link><pubDate>Sat, 19 Aug 2023 11:56:40 +0000</pubDate><guid>https://byalexblog.net/article/react-azure-storage/</guid><description>&lt;img src="https://byalexblog.net/images/react-azure-storage/react-azure-storage-logo.jpg" alt=""> Running a React frontend web application on an Azure Storage account is a great way to host your app with a low cost and high scalability. In this post, we&amp;rsquo;ll go through the steps of setting up a new Azure Storage account and deploying your React app to it.</description></item><item><title>Azure API Management to Azure Service Bus</title><link>https://byalexblog.net/article/azure-apimanagement-to-azure-service-bus/</link><pubDate>Sat, 08 Jul 2023 10:19:45 +0000</pubDate><guid>https://byalexblog.net/article/azure-apimanagement-to-azure-service-bus/</guid><description>&lt;img src="https://byalexblog.net/images/azure-apimanagement-to-azure-service-bus/apim_to_sb.jpg" alt="">
In my &lt;a href="https://byalexblog.net/article/azure-apimanagement-to-azure-storage-account/">previous post&lt;/a> I showed how to use &lt;a href="https://azure.microsoft.com/en-us/products/api-management">Azure API Management&lt;/a> to expose an &lt;a href="https://learn.microsoft.com/en-us/azure/storage/common/storage-account-overview">Azure Storage Account&lt;/a>. In this post I will show how to use Azure API Management to expose an &lt;a href="https://learn.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messaging-overview">Azure Service Bus&lt;/a>.
This combination is useful when you have a fire and forget HTTP endpoint and you expect irregular traffic. For example, you are designing a mobile application crash reporting system. You want to send the crash report to the server and forget about it. You don&amp;rsquo;t want to wait for the response. You don&amp;rsquo;t want to block the user interface. You don&amp;rsquo;t want to retry if the server is not available. It might happen that a new mobile app version has a significant bug and you get a lot of crash reports. In this case, it is reasonable to use Azure Service Bus to queue the crash reports for peak times and process them later.
As in my &lt;a href="https://byalexblog.net/article/azure-apimanagement-to-azure-storage-account/">previous post&lt;/a>, I will use a scenario with two brands (Adidas and Nike) to show you the flexibility of the combination Azure API Management plus Azure Service Bus. I will also define everything in &lt;a href="https://www.terraform.io/">Terraform&lt;/a> so the solution deployment is fully automated.</description></item><item><title>Azure API Management to Azure Storage Account</title><link>https://byalexblog.net/article/azure-apimanagement-to-azure-storage-account/</link><pubDate>Thu, 06 Jul 2023 08:32:23 +0000</pubDate><guid>https://byalexblog.net/article/azure-apimanagement-to-azure-storage-account/</guid><description>&lt;img src="https://byalexblog.net/images/azure-apimanagement-to-azure-storage-account/apim_to_blob.jpg" alt=""> There can be the case when you need to upload a file or metadata to &lt;a href="https://learn.microsoft.com/en-us/azure/storage/common/storage-account-overview">Azure Storage Account&lt;/a> from an application which is outside of your cloud infrastructure. You should not expose your storage account to the internet for that purpose. There are many reasons for that: securuty, flexibility, monitoring etc. The natural solution to acheave the goal is to use something in between of your Azure Storage Account and the public internet. Some kind of HTTP proxy that will manage user authentication, do some simple validations and then pass the request to Storage Account to save the request body data as a blob. &lt;a href="https://azure.microsoft.com/en-us/products/api-management">Azure API Management&lt;/a> is a perfect candidate for that role. It is a fully managed service that means you don&amp;rsquo;t need to create any custom application. It is highly available and scalable. It has a lot of features that can be used for your needs.
In this article I will show how to configure Azure API Management to upload a file to Azure Storage Account.</description></item><item><title>Breaking Through Barriers: Simplifying CD with Automated Azure SQL Schema Changes!</title><link>https://byalexblog.net/article/azure-sql-schema-deployment/</link><pubDate>Sat, 10 Jun 2023 10:57:21 +0000</pubDate><guid>https://byalexblog.net/article/azure-sql-schema-deployment/</guid><description>&lt;img src="https://byalexblog.net/images/azure-sql-schema-deployment/logo.jpg" alt=""> Have you ever tried to deploy a Microsoft SQL database schema to Azure SQL using a linux-based CI/CD pipeline? If you did, you probably know that it is not a trivial task. The reason is that the &lt;a href="https://www.nuget.org/packages/Microsoft.Data.Tools.Msbuild">Microsoft.Data.Tools.Msbuild&lt;/a> package is not available for linux. The package contains MSBuild targets and properties that are used to build and deploy database projects. The package is a part of &lt;a href="https://docs.microsoft.com/en-us/sql/ssdt/download-sql-server-data-tools-ssdt?view=sql-server-ver15">SQL Server Data Tools (SSDT)&lt;/a> and it is not available for linux. So if you want to deploy a database schema to Azure SQL using a linux-based CI/CD pipeline you need to use a different approach. In this article we will see how to deploy a Microsoft SQL database schema to Azure SQL using &lt;strong>any&lt;/strong> linux-based CI/CD pipeline (Gitlab, GitHub, Azure DevOps, etc).</description></item><item><title>Azure Function Serverless Deployment Python</title><link>https://byalexblog.net/article/azure-function-serverless-deployment-python/</link><pubDate>Fri, 26 May 2023 12:03:58 +0000</pubDate><guid>https://byalexblog.net/article/azure-function-serverless-deployment-python/</guid><description>&lt;img src="https://byalexblog.net/images/azure-function-serverless-deployment-python/logo.jpg" alt=""> Consumption plan is the cheapest way to run your Azure Function. However, it has some limitations. For example, you can not use Web Deploy, Docker Container, Source Control, FTP, Cloud sync or Local Git. You can use &lt;a href="https://learn.microsoft.com/en-us/azure/azure-functions/functions-deployment-technologies#external-package-url">External package URL&lt;/a> or &lt;a href="https://learn.microsoft.com/en-us/azure/azure-functions/functions-deployment-technologies#zip-deploy">Zip deploy&lt;/a> instead. In this article I will show you how to deploy Python Azure Function &lt;a href="https://techcommunity.microsoft.com/t5/azure-compute-blog/azure-functions-v2-python-programming-model/ba-p/3665168">Programming Model v2&lt;/a> App to Linux Consumption Azure Function resource using Zip Deployment.</description></item><item><title>Azure Function Serverless Deployment Dotnet</title><link>https://byalexblog.net/article/azure-function-serverless-deployment-dotnet/</link><pubDate>Wed, 24 May 2023 18:53:32 +0000</pubDate><guid>https://byalexblog.net/article/azure-function-serverless-deployment-dotnet/</guid><description>&lt;img src="https://byalexblog.net/images/azure-function-serverless-deployment-dotnet/logo.jpg" alt=""> Consumption plan is the cheapest way to run your Azure Function. However, it has some limitations. For example, you can not use Web Deploy, Docker Container, Source Control, FTP, Cloud sync or Local Git. You can use &lt;a href="https://learn.microsoft.com/en-us/azure/azure-functions/functions-deployment-technologies#external-package-url">External package URL&lt;/a> or &lt;a href="https://learn.microsoft.com/en-us/azure/azure-functions/functions-deployment-technologies#zip-deploy">Zip deploy&lt;/a> instead. In this article I will show you how to deploy Dotnet Isolated Azure Function App to Linux Consumption Azure Function resource using Zip Deployment.</description></item><item><title>Dapper queries synchronized with MSSQL database schema</title><link>https://byalexblog.net/article/dapper-queries-synchronized-with-mssql-database-schema/</link><pubDate>Thu, 25 Aug 2022 12:43:45 +0200</pubDate><guid>https://byalexblog.net/article/dapper-queries-synchronized-with-mssql-database-schema/</guid><description>&lt;img src="https://byalexblog.net/images/dapper-queries-synchronized-with-mssql-database-schema/logo.jpg" alt=""> Dapper is a MicroORM that allows you to control SQL queries you are executing and removes the pain of mapping the dataset results back to your domain model. The thing is that when you specify SQL queries you have to make sure they are valid against the current Database schema. One solution is to use Stored Procedures&amp;hellip; other one is this&amp;hellip;</description></item><item><title>AWS Certificate Manager TLS Certificate import</title><link>https://byalexblog.net/article/aws-certificatemanager-tls-cert-import/</link><pubDate>Tue, 23 Aug 2022 11:18:30 +0200</pubDate><guid>https://byalexblog.net/article/aws-certificatemanager-tls-cert-import/</guid><description>When you are going to use TLS certificate with AWS CloudFront, AWS Elastic Load Balancing, AWS API Gateway or other integrated services you can use that by importing the certificate data to the AWS Certificate Manager.</description></item><item><title>Deploying dotnet6 app on AWS ElasticBeanstalk Graviton2 with HTTPS termination on EC2 instance</title><link>https://byalexblog.net/article/dotnet6-elasticbeanstalk/</link><pubDate>Mon, 22 Aug 2022 10:20:06 +0200</pubDate><guid>https://byalexblog.net/article/dotnet6-elasticbeanstalk/</guid><description>On one of my project it was a requirement to reduce the ElasticBeanstalk hosting costs to minimum for dotnet application. The app is a kind of dashboard with limited audience and nothing heavy inside. I decided to use Graviton2 instances (ARM processors on board) in order to acheave best speed/cost ratio.</description></item><item><title>My current command to format hard drive for linux NAS</title><link>https://byalexblog.net/article/linux-nas-drive-format-command/</link><pubDate>Tue, 03 Aug 2021 21:22:05 +0300</pubDate><guid>https://byalexblog.net/article/linux-nas-drive-format-command/</guid><description>Put it here to just not forget =) Here is my command to format my hard drives for NAS. I came to this when I bought 2 10TB hard drives for Chia coin mining. &lt;code>bash sudo mkfs.ext4 /dev/sde1 -T largefile4 -m 0&lt;/code></description></item><item><title>Azure Api Management Automated Revisions</title><link>https://byalexblog.net/article/azure-api-management-automated-revisions/</link><pubDate>Wed, 28 Jul 2021 23:41:05 +0300</pubDate><guid>https://byalexblog.net/article/azure-api-management-automated-revisions/</guid><description>Powershell script to deploy new WebAPI and release new API Management revision with zero downtime.</description></item><item><title>Future for business analysts</title><link>https://byalexblog.net/article/future-for-business-analysts/</link><pubDate>Thu, 20 Oct 2016 12:12:40 +0300</pubDate><guid>https://byalexblog.net/article/future-for-business-analysts/</guid><description>Software products can be much better if anybody start asking questions about who will use it. We need user researchers called Interaction Designers (IxD) that will prove we are creating something that can be used by people. Where to find them? Business analysts are best people to start looking.</description></item><item><title>3 steps to create integration tests for your ASP.NET MVC 5 application</title><link>https://byalexblog.net/article/3-steps-integration-testing-aspnet-mvc/</link><pubDate>Sun, 02 Oct 2016 09:43:29 +0300</pubDate><guid>https://byalexblog.net/article/3-steps-integration-testing-aspnet-mvc/</guid><description>&lt;p>&lt;img src="https://byalexblog.net/images/3-steps-integration-testing-aspnet-mvc/integration-testing-mock-component.png" alt="">
When you develop an ASP.NET MVC application you should test it anyway. You can cover different parts of your application logic with unit tests or you can create tests that look like user interaction scenarios. These tests have several advantages over unit tests:&lt;/p>
&lt;ul>
&lt;li>These tests are independent of implementation and you can&amp;rsquo;t break your test by refactoring (the only scenario when you should modify your test is functional requirement change).&lt;/li>
&lt;li>These tests are good documentation for your application.&lt;/li>
&lt;li>These tests can give you idea about that your users need and how will they supposed to use concrete feature.&lt;/li>
&lt;/ul></description></item><item><title>Merge SQL databases</title><link>https://byalexblog.net/article/merge-sql-databases/</link><pubDate>Fri, 27 May 2016 11:55:25 +0300</pubDate><guid>https://byalexblog.net/article/merge-sql-databases/</guid><description>Imagine you have 2 databases with identical schema. These databases were working for different application instances for some time. And now you need to merge them together for some reason. You can use different tools to achieve this goal. For example &lt;a href="https://www.devart.com/ru/dbforge/sql/datacompare/">dbForge Data Compare&lt;/a> or &lt;a href="http://www.red-gate.com/products/sql-development/sql-data-compare/">SQL Data Compare&lt;/a>. But these tools cost money and if you don&amp;rsquo;t merge databases every day this is probably not an option for you. Also these tools does not know full specific of your database structure including unique indexes, check constraints and triggers. Another big deal is identity columns that are using as primary keys. For two databases these keys can be same but represent different entities.  In my practice I face database merge task second time and here is how I handle it.</description></item><item><title>RabbitMQ poisoned messages handling</title><link>https://byalexblog.net/article/rabbitmq-poisoned-messages-handeling/</link><pubDate>Tue, 09 Feb 2016 22:59:03 +0300</pubDate><guid>https://byalexblog.net/article/rabbitmq-poisoned-messages-handeling/</guid><description>You never know what will come from remote system. Even if you keep everything under control, there always can be something unexpected. In microservice architecture each component must be ready for everything.</description></item><item><title>Custom domain name for Azure VM</title><link>https://byalexblog.net/article/custom-domain-name-for-azure-vm/</link><pubDate>Sun, 04 Oct 2015 23:33:03 +0300</pubDate><guid>https://byalexblog.net/article/custom-domain-name-for-azure-vm/</guid><description>If you are running VM on Azure you know that your default domain name looks like this: &lt;code>yourservicename.cloudapp.net&lt;/code>. Also public IP address is not static that means you can&amp;rsquo;t use &amp;lsquo;A&amp;rsquo; DNS record on it.</description></item><item><title>Using MSBuild to deploy composite web application</title><link>https://byalexblog.net/article/using-msbuild-to-deploy-composite-web-application/</link><pubDate>Thu, 30 Apr 2015 17:30:52 +0300</pubDate><guid>https://byalexblog.net/article/using-msbuild-to-deploy-composite-web-application/</guid><description>How to deploy AngularJS + ASP.NET Web.API application using MSBuild</description></item><item><title>The biggest problem of all software developers</title><link>https://byalexblog.net/article/the-biggest-problem-of-all-software-developers/</link><pubDate>Sun, 29 Mar 2015 11:16:38 +0300</pubDate><guid>https://byalexblog.net/article/the-biggest-problem-of-all-software-developers/</guid><description>The biggest problem of all software developers</description></item><item><title>Reading user defined columns from database with Entity Framework</title><link>https://byalexblog.net/article/entity-framework-dynamic-columns/</link><pubDate>Thu, 12 Mar 2015 20:43:25 +0300</pubDate><guid>https://byalexblog.net/article/entity-framework-dynamic-columns/</guid><description>Reading user defined columns from database with Entity Framework</description></item></channel></rss>